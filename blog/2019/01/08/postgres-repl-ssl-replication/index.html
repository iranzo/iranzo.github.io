<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Postgres repl SSL replication | Pablo Iranzo Gómez blog</title>
<meta name=keywords content="postgres,FOSS,SSL,replication,federation,Kubernetes,OpenShift"><meta name=description content="Postgres across clusters
For Postgres to work across clusters we do need to have the data being synchronized.
With some other databases we do have some master-master approach, but
usually have very strict requirements on latency, bandwidth, etc that we
cannot solve with On-Premise + external cloud providers.
If the replication is based on the storage level instead, then you face that database servers don’t deal well if the data changes underneath it, so it leads to data corruption, on top of the storage-level issues/requirements as well on bandwidth, latency, etc."><meta name=author content="Pablo Iranzo Gómez"><link rel=canonical href=https://iranzo.io/blog/2019/01/08/postgres-repl-ssl-replication/><meta name=google-site-verification content="Bk4Z5ucHLyPXqlZlj5LzANpYBBSvxqBW4E8i-Kwf-bQ"><meta name=yandex-verification content="993ede96cdfbee95"><link crossorigin=anonymous href=../../../../../assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://iranzo.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://iranzo.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://iranzo.io/favicon-32x32.png><link rel=apple-touch-icon href=https://iranzo.io/apple-touch-icon.png><link rel=mask-icon href=https://iranzo.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://iranzo.io/blog/2019/01/08/postgres-repl-ssl-replication/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-ZL9P943TP1"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-ZL9P943TP1")}</script><meta property="og:url" content="https://iranzo.io/blog/2019/01/08/postgres-repl-ssl-replication/"><meta property="og:site_name" content="Pablo Iranzo Gómez blog"><meta property="og:title" content="Postgres repl SSL replication"><meta property="og:description" content="Postgres across clusters For Postgres to work across clusters we do need to have the data being synchronized.
With some other databases we do have some master-master approach, but usually have very strict requirements on latency, bandwidth, etc that we cannot solve with On-Premise + external cloud providers.
If the replication is based on the storage level instead, then you face that database servers don’t deal well if the data changes underneath it, so it leads to data corruption, on top of the storage-level issues/requirements as well on bandwidth, latency, etc."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2019-01-08T17:30:36+01:00"><meta property="article:modified_time" content="2023-08-25T09:48:47+00:00"><meta property="article:tag" content="Postgres"><meta property="article:tag" content="FOSS"><meta property="article:tag" content="SSL"><meta property="article:tag" content="Replication"><meta property="article:tag" content="Federation"><meta property="article:tag" content="Kubernetes"><meta property="og:image" content="https://iranzo.io/mugshot.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://iranzo.io/mugshot.png"><meta name=twitter:title content="Postgres repl SSL replication"><meta name=twitter:description content="Postgres across clusters
For Postgres to work across clusters we do need to have the data being synchronized.
With some other databases we do have some master-master approach, but
usually have very strict requirements on latency, bandwidth, etc that we
cannot solve with On-Premise + external cloud providers.
If the replication is based on the storage level instead, then you face that database servers don’t deal well if the data changes underneath it, so it leads to data corruption, on top of the storage-level issues/requirements as well on bandwidth, latency, etc."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blogs","item":"https://iranzo.io/blog/"},{"@type":"ListItem","position":2,"name":"Postgres repl SSL replication","item":"https://iranzo.io/blog/2019/01/08/postgres-repl-ssl-replication/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Postgres repl SSL replication","name":"Postgres repl SSL replication","description":"Postgres across clusters For Postgres to work across clusters we do need to have the data being synchronized.\nWith some other databases we do have some master-master approach, but usually have very strict requirements on latency, bandwidth, etc that we cannot solve with On-Premise + external cloud providers.\nIf the replication is based on the storage level instead, then you face that database servers don’t deal well if the data changes underneath it, so it leads to data corruption, on top of the storage-level issues/requirements as well on bandwidth, latency, etc.\n","keywords":["postgres","FOSS","SSL","replication","federation","Kubernetes","OpenShift"],"articleBody":"Postgres across clusters For Postgres to work across clusters we do need to have the data being synchronized.\nWith some other databases we do have some master-master approach, but usually have very strict requirements on latency, bandwidth, etc that we cannot solve with On-Premise + external cloud providers.\nIf the replication is based on the storage level instead, then you face that database servers don’t deal well if the data changes underneath it, so it leads to data corruption, on top of the storage-level issues/requirements as well on bandwidth, latency, etc.\nOther approaches http://evol-monkey.blogspot.com/2015/10/postgresql-94-streaming-replication.html https://hackernoon.com/postgresql-cluster-into-kubernetes-cluster-f353cde212de PostgreSQL streaming replication over SSL There are several ways to accomplish this if you do a quick search on a web crawler, but we’ve gone the PSQL Streaming replication over SSL for our environment.\nA replication slot is (as defined in documentation)\nReplication slots provide an automated way to ensure that the master does not remove WAL segments until they have been received by all standby’s, and that the master does not remove rows which could cause a recovery conflict even when the standby is disconnected.\nBackground Quay requires a database that is available for each instance and provides required redundancy/replication Replicating via storage can lead to issues as the files will change underneath postgres Galera approach for MySQL (multi-master) is known to have issues even when running on the same cluster For Federation we do want applications to run in different clusters, so an approach where a hot-standby is ready will probably overcome the limitations of master-master and the requirements for available database for all quay instances. Investigation We started to investigate how others approached this situation and similar to what was done for another part of the setup for MongoDB, we went testing via replication over SSL.\nWe also checked several of the approaches, but one of them, PostDock images were lacking SSL support, but still had a nice way to do several overrides for configuration, etc via environment variables, which made them ideal for testing in an OpenShift/Kubernetes environment.\nThe environments we plan to use are:\nAIT cluster LEO cluster PIT cluster SSL For the SSL setup side we did:\nCreate Postgres Certs Seems that Postgres doesn’t check the certificate for the host ‘by default’, but just uses the certificate to encrypt, but still we did create the certificates using the name of the application in it for future usage.\nUsing the same certificate with all server names, we can also federate a single secret containing those certs rather than creating one SSL secret for each cluster.\n$$./generate-cert.sh postgres$$\nWith output:\n$$2018/11/29 15:04:29 [INFO] generate received request 2018/11/29 15:04:29 [INFO] received CSR 2018/11/29 15:04:29 [INFO] generating key: rsa-2048 2018/11/29 15:04:29 [INFO] encoded CSR 2018/11/29 15:04:29 [INFO] signed certificate with serial number 34111709152443674697969629831350216041253590538$$\nNow, we do have all the required certificates for postgres generated.\n-rw-r--r--. 1 iranzo iranzo 1001 nov 29 15:04 postgres.csr -rw-rw-r--. 1 iranzo iranzo 208 nov 29 15:04 postgres-csr.json -rw-------. 1 iranzo iranzo 1679 nov 29 15:04 postgres-key.pem -rw-rw-r--. 1 iranzo iranzo 1753 nov 29 15:04 postgres.pem Our setup configuration Setup:\nLEO will be the ‘master’ with $PGDATA at /var/lib/postgresql/data in a local volume AIT will be the ‘slave’ with $PGDATA at /var/lib/postgresql/data in a local volume PIT will be the ‘slave’ with $PGDATA at /var/lib/postgresql/data in a local volume The first issue we found is that by default, PostDock lacks the SSL support, but as we were allowed to define settings for the configuration files we could override the settings via a variable named CONFIGS set to ssl:on,ssl_cert_file:'/etc/postgresql/server.crt',ssl_key_file:'/etc/postgresql/server.key'.\nThis required to craft a custom image (quay.io/iranzo/postdock:sslkeyschown) that we submitted as PR to PostDock.\nIn the meantime, we did use https://quay.io to store our image and rebuild whenever we changed the code at our custom repo.\nThe changes in our image are very simple:\ndiff --git a/src/pgsql/bin/postgres/entrypoint.sh b/src/pgsql/bin/postgres/entrypoint.sh index b09652c..1298dcb 100755 --- a/src/pgsql/bin/postgres/entrypoint.sh +++ b/src/pgsql/bin/postgres/entrypoint.sh @@ -42,7 +42,25 @@ else fi fi -KEYS=$(egrep '(ssl_cert_file|ssl_key_file)' $PGDATA/postgresql.conf|cut -d \"=\" -f 2-) + +echo \"\u003e\u003e\u003e Trying to configure SSL\" +# Tweak keys to avoid permission issues: +ORIGKEYS=$(echo $CONFIGS|tr \",\" \"\\n\"|egrep '(ssl_cert_file|ssl_key_file)'|cut -d \":\" -f 2-|tr \"\\n\" \" \"|tr -d \"\\'\") +KEYS=\"\" + +echo \"\u003e\u003e\u003e Trying to move ${ORIGKEYS} to proper folder\" +for file in ${ORIGKEYS}; do + # Check for file or link pointing to file + if [ -e /pg-ssl/$(basename ${file}) ]; then + echo \"\u003e\u003e\u003e Copying SSL file from /pg-ssl/$(basename ${file}) to ${file}\" + mkdir -p $(dirname ${file}) + cat /pg-ssl/$(basename ${file}) \u003e ${file} + KEYS=\"$KEYS ${file}\" + else + echo \"\u003e\u003e\u003e ERROR: SSL File ${file} doesn't exist on disk\" + fi +done + chown -R postgres $PGDATA $KEYS \u0026\u0026 chmod -R 0700 $PGDATA $KEYS source /usr/local/bin/cluster/repmgr/configure.sh From this, and once ‘Quay’ builds our image, we should, in the namespace for our project, add a new application via ‘Deploy image’ with quay.io/iranzo/postdock:sslkeyschown (sources at https://github.com/iranzo/PostDock)\nThe application will ask for some configuration options, name for the new application, etc\nWe must configure some environment variables:\nEnvironment configuration PARTNER_NODES: IP’s of: postgres-leo.apps.e2e.bos.example.com,postgres-ait.apps.e2e.bos.example.com,postgres-aws.apps.e2e.bos.example.com (from below, but EXCLUDING the one we’re that we’ll be putting in CLUSTER_NODE_NETWORK_NAME) LEO: 10.19.227.153 AIT: 10.19.115.226 AWS: internal-aba91353afe1c11e89f350a50403e669-443870799.us-east-1.elb.amazonaws.com CLUSTER_NAME: quaydatabase POSTGRES_DB: quaydb DB_USERS: replication_user:replication_pass,quayuser:quaypass CONFIGS: ssl:on,ssl_cert_file:'/etc/postgresql/server.crt',ssl_key_file:'/etc/postgresql/server.key' NODE_NAME: Identifying name for this instance NODE_ID: $(NUMBER DIFFERENT FOR EACH NODE + 1000, f.e. 1002) CLUSTER_NODE_NETWORK_NAME: $(SAME AS NODE_NAME that would go in PARTNER NODES) REPLICATION_HOST: “postgres” (name of app in deployment) We did raise/update some issues:\nhttps://github.com/paunin/PostDock/issues/124 https://github.com/paunin/PostDock/issues/202 https://github.com/paunin/PostDock/issues/203 But finally as we had to build our own modified image we were able to circumvent them.\nWe did configure some more things to pass the certificates and key to the pods:\nConfigure a secret with server.crt and server.key based on the postgres.pem and postgres-key.pem for each one of them. As we’re using a secret for storing the certificates, we’ll use a volume exposing it to the host via the path /pg-ssl\n- mountPath: /pg-ssl name: volume-yisiz readOnly: true Our patched image, will find and move the certificates to their final destination (specified via environment variable in CONFIGS).\nThis image, also ensures valid permissions and ownership so that postgres can start and answer ‘SSL’ via a:\niranzo   iranzo-save  …  RH  syseng  pit-hybrid  psql -h localhost -U replication_user -W replication_db -p 5432 Password for user replication_user: psql (10.6) SSL connection (protocol: TLSv1.2, cipher: ECDHE-RSA-AES256-GCM-SHA384, bits: 256, compression: disabled) replication_db=# \\dt Did not find any relations. replication_db=# Additional settings Configure a volume for storing permanent data in /var/lib/postgresql/data so that is kept and not destroyed on pod destroy. The bittersweet wrap-up At this point we do have the postgres image started with SSL, however:\nIn order to use replication between environments, we need a way to access postgres The creation and configuration of SSL setup gets us a bit closer to it OpenShift HAPROXY requires SNI-capable client, which is not1 the case, hence we still cannot have the traffic get into the postgres instance and hence, replication doesn’t start as there’s no communication. All attempts to use a router (that only permits http and https or TLS-with-SNI) failed completely, as PSQL doesn’t yet have the support in place, failed, even some other hacks on initialization scripts to use the alternate port instead.\nUnfortunately, this became a major blocker at this time, not allowing us to setup a replicated postgres cluster across different OpenShift Clusters to have it as a database we can rely for setting up Quay on top.\nThe plot twist After finding no more ways, we discussed with our team members for putting more brains in this, and in conversations with Pep, Mario and Ryan, it was suggested to instead use a LoadBalancer IP, that imposes no restrictions on the traffic, this however could only be accomplished on 3 environments (LEO, AIT and AWS)\nAs AWS seems to have no DNS resolution, we’re limited to use IP’s in the server name (for the CLUSTER_NODE_NETWORK_NAME) so that in case of failover, AWS can reach them.\nWith the current setup, we only needed to define ‘persistent’ storage for postgres so in case all three pods were destroyed at the same time, we do have some data to start over.\nThe final steps, outlined above in Our setup configuration, were updated to use:\nPARTNER_NODES containing the LB IP address for the Load Balancer defined in each environment EXCEPT our own\nCLUSTER_NODE_NETWORK_NAME: our LB IP as it would go in PARTNER_NODES for other clusters\nPARTNER_NODES: IP’s of: postgres-leo.apps.e2e.bos.example.com,postgres-ait.apps.e2e.bos.example.com,postgres-aws.apps.e2e.bos.example.com (from below, but EXCLUDING the one we’re that we’ll be putting in CLUSTER_NODE_NETWORK_NAME)\nLEO: 10.19.227.153 AIT: 10.19.115.226 AWS: internal-aba91353afe1c11e89f350a50403e669-443870799.us-east-1.elb.amazonaws.com NODE_ID: $(NUMBER DIFFERENT FOR EACH NODE + 1000, f.e. 1002)\nCLUSTER_NODE_NETWORK_NAME: $(SAME AS NODE_NAME that would go in PARTNER NODES)\nREPLICATION_HOST: “postgres” (name of app in deployment)\nWith this approach, the LoadBalancer effectively passes the data on port 5432 (even if it’s not SSL), and the cluster can form and start replication of data.\nSo next steps are:\nDefine DNS name pointing to all 3 IP’s that we can configure on apps Rely on psql standby to work in read-only mode and providing service Setup Quay to use that psql DNS name Automate the setup, including Quay ENV variable for storage ‘closer’ to each cluster. Thread on psql-hackers and pinged by us Enjoy! (and if you do, you can Buy Me a Coffee ) ↩︎\n","wordCount":"1543","inLanguage":"en","image":"https://iranzo.io/mugshot.png","datePublished":"2019-01-08T17:30:36+01:00","dateModified":"2023-08-25T09:48:47.162Z","author":{"@type":"Person","name":"Pablo Iranzo Gómez"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://iranzo.io/blog/2019/01/08/postgres-repl-ssl-replication/"},"publisher":{"@type":"Organization","name":"Pablo Iranzo Gómez blog","logo":{"@type":"ImageObject","url":"https://iranzo.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://iranzo.io/ accesskey=h title="Home (Alt + H)"><img src=https://iranzo.io/apple-icon-152x152.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://iranzo.io/es/ title=Spanish aria-label=Spanish>Es</a></li></ul></div></div><ul id=menu><li><a href=https://iranzo.io/ title=🏠Home><span>🏠Home</span></a></li><li><a href=https://iranzo.io/about/ title=🗒️About><span>🗒️About</span></a></li><li><a href=https://iranzo.io/redken_bot/ title=🐘redken_bot><span>🐘redken_bot</span></a></li><li><a href=https://iranzo.io/projects/ title=📐Projects><span>📐Projects</span></a></li><li><a href=https://iranzo.io/archives/ title="🗄️ Archives"><span>🗄️ Archives</span></a></li><li><a href=https://iranzo.io/categories/ title=🗺️Categories><span>🗺️Categories</span></a></li><li><a href=https://iranzo.io/tags/ title=🏷️Tags><span>🏷️Tags</span></a></li><li><a href=https://iranzo.io/search title="🔎Search (Alt + /)" accesskey=/><span>🔎Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://iranzo.io/>Home</a>&nbsp;»&nbsp;<a href=https://iranzo.io/blog/>Blogs</a></div><h1 class="post-title entry-hint-parent">Postgres repl SSL replication</h1><div class=post-meta><span title='2019-01-08 17:30:36 +0100 +0100'>January 8, 2019</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;Pablo Iranzo Gómez</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#postgres-across-clusters aria-label="Postgres across clusters">Postgres across clusters</a><ul><li><a href=#other-approaches aria-label="Other approaches">Other approaches</a></li></ul></li><li><a href=#postgresql-streaming-replication-over-ssl aria-label="PostgreSQL streaming replication over SSL">PostgreSQL streaming replication over SSL</a><ul><li><a href=#background aria-label=Background>Background</a></li><li><a href=#investigation aria-label=Investigation>Investigation</a></li><li><a href=#ssl aria-label=SSL>SSL</a><ul><li><a href=#create-postgres-certs aria-label="Create Postgres Certs">Create Postgres Certs</a></li><li><a href=#our-setup-configuration aria-label="Our setup configuration">Our setup configuration</a></li><li><a href=#environment-configuration aria-label="Environment configuration">Environment configuration</a></li></ul></li><li><a href=#additional-settings aria-label="Additional settings">Additional settings</a></li><li><a href=#the-bittersweet-wrap-up aria-label="The bittersweet wrap-up">The bittersweet wrap-up</a></li><li><a href=#the-plot-twist aria-label="The plot twist">The plot twist</a></li></ul></li></ul></div></details></div><div class=post-content><h1 id=postgres-across-clusters>Postgres across clusters<a hidden class=anchor aria-hidden=true href=#postgres-across-clusters>#</a></h1><p>For Postgres to work across clusters we do need to have the data being synchronized.</p><p>With some other databases we do have some master-master approach, but
usually have very strict requirements on latency, bandwidth, etc that we
cannot solve with On-Premise + external cloud providers.</p><p>If the replication is based on the storage level instead, then you face that database servers don’t deal well if the data changes underneath it, so it leads to data corruption, on top of the storage-level issues/requirements as well on bandwidth, latency, etc.</p><h2 id=other-approaches>Other approaches<a hidden class=anchor aria-hidden=true href=#other-approaches>#</a></h2><ul><li><a href=http://evol-monkey.blogspot.com/2015/10/postgresql-94-streaming-replication.html>http://evol-monkey.blogspot.com/2015/10/postgresql-94-streaming-replication.html</a></li><li><a href=https://hackernoon.com/postgresql-cluster-into-kubernetes-cluster-f353cde212de>https://hackernoon.com/postgresql-cluster-into-kubernetes-cluster-f353cde212de</a></li></ul><h1 id=postgresql-streaming-replication-over-ssl>PostgreSQL streaming replication over SSL<a hidden class=anchor aria-hidden=true href=#postgresql-streaming-replication-over-ssl>#</a></h1><p>There are several ways to accomplish this if you do a quick search on a web crawler, but we&rsquo;ve gone the PSQL Streaming replication over SSL for our environment.</p><p>A replication slot is (as defined in <a href=https://www.postgresql.org/docs/9.4/warm-standby.html#STREAMING-REPLICATION-SLOTS>documentation</a>)</p><blockquote><p>Replication slots provide an automated way to ensure that the master does not remove WAL segments until they have been received by all
standby&rsquo;s, and that the master does not remove rows which could cause a recovery conflict even when the standby is disconnected.</p></blockquote><h2 id=background>Background<a hidden class=anchor aria-hidden=true href=#background>#</a></h2><ul><li>Quay requires a database that is available for each instance and provides required redundancy/replication</li><li>Replicating via storage can lead to issues as the files will change underneath postgres</li><li>Galera approach for MySQL (multi-master) is known to have issues even when running on the same cluster</li><li>For Federation we do want applications to run in different clusters, so an approach where a hot-standby is ready will probably overcome the limitations of master-master and the requirements for available database for all quay instances.</li></ul><h2 id=investigation>Investigation<a hidden class=anchor aria-hidden=true href=#investigation>#</a></h2><p>We started to investigate <a href=../../../../../blog/2019/01/08/postgres-repl-ssl-replication/#other-approach>how others approached</a> this situation and similar to what was done for another part of the setup for
MongoDB, we went testing via replication over SSL.</p><p>We also checked several of the approaches, but one of them, PostDock images were lacking SSL support, but still had a nice way to do several overrides for configuration, etc via environment variables, which made them ideal for testing in an OpenShift/Kubernetes environment.</p><p>The environments we plan to use are:</p><ul><li>AIT cluster</li><li>LEO cluster</li><li>PIT cluster</li></ul><h2 id=ssl>SSL<a hidden class=anchor aria-hidden=true href=#ssl>#</a></h2><p>For the SSL setup side we did:</p><h3 id=create-postgres-certs>Create Postgres Certs<a hidden class=anchor aria-hidden=true href=#create-postgres-certs>#</a></h3><p>Seems that Postgres doesn&rsquo;t check the certificate for the host &lsquo;by default&rsquo;, but just uses the certificate to encrypt, but still we did create the certificates using the name of the application in it for future usage.</p><p>Using the same certificate with all server names, we can also federate a
single secret containing those certs rather than creating one SSL secret for
each cluster.</p><p>$$./generate-cert.sh postgres$$</p><p>With output:</p><p>$$2018/11/29 15:04:29 [INFO] generate received request
2018/11/29 15:04:29 [INFO] received CSR
2018/11/29 15:04:29 [INFO] generating key: rsa-2048
2018/11/29 15:04:29 [INFO] encoded CSR
2018/11/29 15:04:29 [INFO] signed certificate with serial number 34111709152443674697969629831350216041253590538$$</p><p>Now, we do have all the required certificates for postgres generated.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>-rw-r--r--. <span style=color:#ae81ff>1</span> iranzo iranzo <span style=color:#ae81ff>1001</span> nov <span style=color:#ae81ff>29</span> 15:04 postgres.csr
</span></span><span style=display:flex><span>-rw-rw-r--. <span style=color:#ae81ff>1</span> iranzo iranzo  <span style=color:#ae81ff>208</span> nov <span style=color:#ae81ff>29</span> 15:04 postgres-csr.json
</span></span><span style=display:flex><span>-rw-------. <span style=color:#ae81ff>1</span> iranzo iranzo <span style=color:#ae81ff>1679</span> nov <span style=color:#ae81ff>29</span> 15:04 postgres-key.pem
</span></span><span style=display:flex><span>-rw-rw-r--. <span style=color:#ae81ff>1</span> iranzo iranzo <span style=color:#ae81ff>1753</span> nov <span style=color:#ae81ff>29</span> 15:04 postgres.pem
</span></span></code></pre></div><h3 id=our-setup-configuration>Our setup configuration<a hidden class=anchor aria-hidden=true href=#our-setup-configuration>#</a></h3><p>Setup:</p><ul><li>LEO will be the &lsquo;master&rsquo; with <code>$PGDATA</code> at <code>/var/lib/postgresql/data</code> in a local volume</li><li>AIT will be the &lsquo;slave&rsquo; with <code>$PGDATA</code> at <code>/var/lib/postgresql/data</code> in a local volume</li><li>PIT will be the &lsquo;slave&rsquo; with <code>$PGDATA</code> at <code>/var/lib/postgresql/data</code> in a local volume</li></ul><p>The first issue we found is that by default, PostDock lacks the SSL support,
but as we were allowed to define settings for the configuration files we
could override the settings via a variable named <code>CONFIGS</code> set to
<code>ssl:on,ssl_cert_file:'/etc/postgresql/server.crt',ssl_key_file:'/etc/postgresql/server.key'</code>.</p><p>This required to craft a custom image (<code>quay.io/iranzo/postdock:sslkeyschown</code>) that we submitted as <a href=https://github.com/paunin/PostDock/pull/205>PR to PostDock</a>.</p><p>In the meantime, we did use <a href=https://quay.io>https://quay.io</a> to store our image and rebuild whenever we changed the code at our custom repo.</p><p>The changes in our image are very simple:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff><span style=display:flex><span>diff --git a/src/pgsql/bin/postgres/entrypoint.sh b/src/pgsql/bin/postgres/entrypoint.sh
</span></span><span style=display:flex><span>index b09652c..1298dcb 100755
</span></span><span style=display:flex><span><span style=color:#f92672>--- a/src/pgsql/bin/postgres/entrypoint.sh
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+++ b/src/pgsql/bin/postgres/entrypoint.sh
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span><span style=color:#75715e>@@ -42,7 +42,25 @@ else
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>     fi
</span></span><span style=display:flex><span> fi
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>-KEYS=$(egrep &#39;(ssl_cert_file|ssl_key_file)&#39; $PGDATA/postgresql.conf|cut -d &#34;=&#34; -f 2-)
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+echo &#34;&gt;&gt;&gt; Trying to configure SSL&#34;
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+# Tweak keys to avoid permission issues:
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+ORIGKEYS=$(echo $CONFIGS|tr &#34;,&#34; &#34;\n&#34;|egrep &#39;(ssl_cert_file|ssl_key_file)&#39;|cut -d &#34;:&#34; -f 2-|tr &#34;\n&#34; &#34; &#34;|tr -d &#34;\&#39;&#34;)
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+KEYS=&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+echo &#34;&gt;&gt;&gt; Trying to move ${ORIGKEYS} to proper folder&#34;
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+for file in ${ORIGKEYS}; do
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+    # Check for file or link pointing to file
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+    if [ -e /pg-ssl/$(basename ${file}) ]; then
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+        echo &#34;&gt;&gt;&gt; Copying SSL file from /pg-ssl/$(basename ${file}) to ${file}&#34;
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+        mkdir -p $(dirname ${file})
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+        cat /pg-ssl/$(basename ${file}) &gt; ${file}
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+        KEYS=&#34;$KEYS ${file}&#34;
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+    else
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+        echo &#34;&gt;&gt;&gt; ERROR: SSL File ${file} doesn&#39;t exist on disk&#34;
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+    fi
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+done
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span> chown -R postgres $PGDATA $KEYS &amp;&amp; chmod -R 0700 $PGDATA $KEYS
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span> source /usr/local/bin/cluster/repmgr/configure.sh
</span></span></code></pre></div><p>From this, and once &lsquo;Quay&rsquo; builds our image, we should, in the namespace for
our project, add a new application via &lsquo;Deploy image&rsquo; with
<code>quay.io/iranzo/postdock:sslkeyschown</code> (sources at
<a href=https://github.com/iranzo/PostDock>https://github.com/iranzo/PostDock</a>)</p><p>The application will ask for some configuration options, name for the new application, etc</p><p>We must configure some environment variables:</p><h3 id=environment-configuration>Environment configuration<a hidden class=anchor aria-hidden=true href=#environment-configuration>#</a></h3><ul><li><code>PARTNER_NODES</code>: IP&rsquo;s of: postgres-leo.apps.e2e.bos.example.com,postgres-ait.apps.e2e.bos.example.com,postgres-aws.apps.e2e.bos.example.com (from below, but EXCLUDING the one we&rsquo;re that we&rsquo;ll be putting in CLUSTER_NODE_NETWORK_NAME)<ul><li>LEO: 10.19.227.153</li><li>AIT: 10.19.115.226</li><li>AWS: internal-aba91353afe1c11e89f350a50403e669-443870799.us-east-1.elb.amazonaws.com</li></ul></li><li><code>CLUSTER_NAME</code>: <code>quaydatabase</code></li><li><code>POSTGRES_DB</code>: <code>quaydb</code></li><li><code>DB_USERS</code>: <code>replication_user:replication_pass,quayuser:quaypass</code></li><li><code>CONFIGS</code>: <code>ssl:on,ssl_cert_file:'/etc/postgresql/server.crt',ssl_key_file:'/etc/postgresql/server.key'</code></li><li><code>NODE_NAME</code>: Identifying name for this instance</li><li><code>NODE_ID</code>: $(NUMBER DIFFERENT FOR EACH NODE + 1000, f.e. 1002)</li><li><code>CLUSTER_NODE_NETWORK_NAME</code>: $(SAME AS NODE_NAME that would go in PARTNER NODES)</li><li><code>REPLICATION_HOST</code>: &ldquo;postgres&rdquo; (name of app in deployment)</li></ul><p>We did raise/update some issues:</p><ul><li><a href=https://github.com/paunin/PostDock/issues/124>https://github.com/paunin/PostDock/issues/124</a></li><li><a href=https://github.com/paunin/PostDock/issues/202>https://github.com/paunin/PostDock/issues/202</a></li><li><a href=https://github.com/paunin/PostDock/issues/203>https://github.com/paunin/PostDock/issues/203</a></li></ul><p>But finally as we had to build our own modified image we were able to circumvent them.</p><p>We did configure some more things to pass the certificates and key to the pods:</p><ul><li>Configure a secret with <code>server.crt</code> and <code>server.key</code> based on the <code>postgres.pem</code> and <code>postgres-key.pem</code> for each one of them.</li></ul><p>As we&rsquo;re using a secret for storing the certificates, we&rsquo;ll use a volume exposing it to the host via the path <code>/pg-ssl</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>    - <span style=color:#f92672>mountPath</span>: <span style=color:#ae81ff>/pg-ssl</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>name</span>: <span style=color:#ae81ff>volume-yisiz</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>readOnly</span>: <span style=color:#66d9ef>true</span>
</span></span></code></pre></div><p>Our patched image, will find and move the certificates to their final destination (specified via environment variable in <code>CONFIGS</code>).</p><p>This image, also ensures valid permissions and ownership so that postgres can start and answer &lsquo;SSL&rsquo; via a:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span> iranzo   iranzo-save  …  RH  syseng  pit-hybrid  psql -h localhost -U replication_user -W replication_db -p <span style=color:#ae81ff>5432</span>
</span></span><span style=display:flex><span>Password <span style=color:#66d9ef>for</span> user replication_user:
</span></span><span style=display:flex><span>psql <span style=color:#f92672>(</span>10.6<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>SSL connection <span style=color:#f92672>(</span>protocol: TLSv1.2, cipher: ECDHE-RSA-AES256-GCM-SHA384, bits: 256, compression: disabled<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>replication_db<span style=color:#f92672>=</span><span style=color:#75715e># \dt</span>
</span></span><span style=display:flex><span>Did not find any relations.
</span></span><span style=display:flex><span>replication_db<span style=color:#f92672>=</span><span style=color:#75715e>#</span>
</span></span></code></pre></div><h2 id=additional-settings>Additional settings<a hidden class=anchor aria-hidden=true href=#additional-settings>#</a></h2><ul><li>Configure a volume for storing permanent data in <code>/var/lib/postgresql/data</code> so that is kept and not destroyed on pod destroy.</li></ul><h2 id=the-bittersweet-wrap-up>The bittersweet wrap-up<a hidden class=anchor aria-hidden=true href=#the-bittersweet-wrap-up>#</a></h2><p>At this point we do have the postgres image started with SSL, however:</p><ul><li>In order to use replication between environments, we need a way to access postgres</li><li>The creation and configuration of SSL setup gets us a bit closer to it</li><li>OpenShift <code>HAPROXY</code> requires SNI-capable client, which is not<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> the case, hence we still cannot have the traffic get into the postgres instance and hence, replication doesn&rsquo;t start as there&rsquo;s no communication.</li></ul><p>All attempts to use a router (that only permits http and https or TLS-with-SNI) failed completely, as PSQL doesn&rsquo;t yet have the support in place, failed, even some other hacks on initialization scripts to use the alternate port instead.</p><p>Unfortunately, this became a major blocker at this time, not allowing us to setup a replicated postgres cluster across different OpenShift Clusters to have it as a database we can rely for setting up Quay on top.</p><h2 id=the-plot-twist>The plot twist<a hidden class=anchor aria-hidden=true href=#the-plot-twist>#</a></h2><p>After finding no more ways, we discussed with our team members for putting more brains in this, and in conversations with Pep, Mario and Ryan, it was suggested to instead use a LoadBalancer IP, that imposes no restrictions on the traffic, this however could only be accomplished on 3 environments (LEO, AIT and AWS)</p><p>As AWS seems to have no DNS resolution, we&rsquo;re limited to use IP&rsquo;s in the server name (for the CLUSTER_NODE_NETWORK_NAME) so that in case of failover, AWS can reach them.</p><p>With the current setup, we only needed to define &lsquo;persistent&rsquo; storage for postgres so in case all three pods were destroyed at the same time, we do have some data to start over.</p><p>The final steps, outlined above in <a href=../../../../../blog/2019/01/08/postgres-repl-ssl-replication/#our-setup-configuration>Our setup configuration</a>, were updated to use:</p><ul><li><p>PARTNER_NODES containing the LB IP address for the Load Balancer defined in each environment EXCEPT our own</p></li><li><p>CLUSTER_NODE_NETWORK_NAME: our LB IP as it would go in PARTNER_NODES for other clusters</p></li><li><p>PARTNER_NODES: IP&rsquo;s of: postgres-leo.apps.e2e.bos.example.com,postgres-ait.apps.e2e.bos.example.com,postgres-aws.apps.e2e.bos.example.com (from below, but EXCLUDING the one we&rsquo;re that we&rsquo;ll be putting in CLUSTER_NODE_NETWORK_NAME)</p><ul><li>LEO: 10.19.227.153</li><li>AIT: 10.19.115.226</li><li>AWS: internal-aba91353afe1c11e89f350a50403e669-443870799.us-east-1.elb.amazonaws.com</li></ul></li><li><p>NODE_ID: $(NUMBER DIFFERENT FOR EACH NODE + 1000, f.e. 1002)</p></li><li><p>CLUSTER_NODE_NETWORK_NAME: $(SAME AS NODE_NAME that would go in PARTNER NODES)</p></li><li><p>REPLICATION_HOST: &ldquo;postgres&rdquo; (name of app in deployment)</p></li></ul><p>With this approach, the LoadBalancer effectively passes the data on port 5432 (even if it&rsquo;s not SSL), and the cluster can form and start replication of data.</p><p>So next steps are:</p><ul><li>Define DNS name pointing to all 3 IP&rsquo;s that we can configure on apps</li><li>Rely on psql standby to work in read-only mode and providing service</li><li>Setup Quay to use that psql DNS name</li><li>Automate the setup, including Quay <code>ENV</code> variable for storage &lsquo;closer&rsquo; to each cluster.</li></ul><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href=https://www.postgresql.org/message-id/CAPPwrB_tsOw8MtVaA_DFyOFRY2ohNdvMnLoA_JRr3yB67Rggmg%40mail.gmail.com>Thread on psql-hackers</a> and <a href=https://www.postgresql.org/message-id/20181211145240.GL20222%40redhat.com>pinged by us</a><p>Enjoy! (and if you do, you can
<a href=https://ko-fi.com/I2I4KDA0V target=_blank><img src=https://storage.ko-fi.com/cdn/brandasset/kofi_s_logo_nolabel.png height=36 style=border:0;height:36px;vertical-align:middle;display:inline-block border=0>
</img>
Buy Me a Coffee
</a>)</p>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://iranzo.io/tags/postgres/>Postgres</a></li><li><a href=https://iranzo.io/tags/foss/>FOSS</a></li><li><a href=https://iranzo.io/tags/ssl/>SSL</a></li><li><a href=https://iranzo.io/tags/replication/>Replication</a></li><li><a href=https://iranzo.io/tags/federation/>Federation</a></li><li><a href=https://iranzo.io/tags/kubernetes/>Kubernetes</a></li><li><a href=https://iranzo.io/tags/openshift/>OpenShift</a></li></ul><nav class=paginav><a class=prev href=https://iranzo.io/blog/2019/01/08/osp-director-baremetal-hypervisor-for-coreos/><span class=title>« Prev</span><br><span>OSP Director baremetal hypervisor for CoreOS</span>
</a><a class=next href=https://iranzo.io/blog/2019/01/08/quay-for-federation/><span class=title>Next »</span><br><span>Quay for Federation</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Postgres repl SSL replication on x" href="https://x.com/intent/tweet/?text=Postgres%20repl%20SSL%20replication&amp;url=https%3a%2f%2firanzo.io%2fblog%2f2019%2f01%2f08%2fpostgres-repl-ssl-replication%2f&amp;hashtags=postgres%2cFOSS%2cSSL%2creplication%2cfederation%2cKubernetes%2cOpenShift"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Postgres repl SSL replication on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2firanzo.io%2fblog%2f2019%2f01%2f08%2fpostgres-repl-ssl-replication%2f&amp;title=Postgres%20repl%20SSL%20replication&amp;summary=Postgres%20repl%20SSL%20replication&amp;source=https%3a%2f%2firanzo.io%2fblog%2f2019%2f01%2f08%2fpostgres-repl-ssl-replication%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Postgres repl SSL replication on reddit" href="https://reddit.com/submit?url=https%3a%2f%2firanzo.io%2fblog%2f2019%2f01%2f08%2fpostgres-repl-ssl-replication%2f&title=Postgres%20repl%20SSL%20replication"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Postgres repl SSL replication on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2firanzo.io%2fblog%2f2019%2f01%2f08%2fpostgres-repl-ssl-replication%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Postgres repl SSL replication on whatsapp" href="https://api.whatsapp.com/send?text=Postgres%20repl%20SSL%20replication%20-%20https%3a%2f%2firanzo.io%2fblog%2f2019%2f01%2f08%2fpostgres-repl-ssl-replication%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Postgres repl SSL replication on telegram" href="https://telegram.me/share/url?text=Postgres%20repl%20SSL%20replication&amp;url=https%3a%2f%2firanzo.io%2fblog%2f2019%2f01%2f08%2fpostgres-repl-ssl-replication%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Postgres repl SSL replication on ycombinator" href="https://news.ycombinator.com/submitlink?t=Postgres%20repl%20SSL%20replication&u=https%3a%2f%2firanzo.io%2fblog%2f2019%2f01%2f08%2fpostgres-repl-ssl-replication%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://iranzo.io/>Pablo Iranzo Gómez blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><center><small>This blog is a participant in the Amazon Associate Program, an affiliate advertising program designed to provide a means for sites to earn advertising fees by advertising and linking to Amazon.</small></center><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>