<!doctype html><html lang=es dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>iSCSI y Clustering en RHEL/CentOS | Pablo Iranzo G√≥mez blog</title><meta name=keywords content="cluster,rhel,centos,foss"><meta name=description content="Introducci√≥n
Durante la √∫ltima semana estuve jugando de nuevo con iSCSI en el curso de RH436 Enterprise Clustering and Storage Management. Hace tiempo hab√≠a seguido dos art√≠culos Instalando un target iSCSI y su continuaci√≥n Montando un iniciador iSCSI.
iSCSI es una tecnolog√≠a que permite acceder a almacenamiento remoto como si de unidades locales se tratara. A nivel &lsquo;barato&rsquo;, podemos utilizar el espacio de un servidor central del que hacemos copias de seguridad, etc para ofrecer ese almacenamiento a distintas m√°quinas."><meta name=author content="Pablo Iranzo G√≥mez"><link rel=canonical href=https://iranzo.io/es/blog/2008/12/13/iscsi-y-clustering-en-rhel/centos/><meta name=google-site-verification content="Bk4Z5ucHLyPXqlZlj5LzANpYBBSvxqBW4E8i-Kwf-bQ"><meta name=yandex-verification content="993ede96cdfbee95"><link crossorigin=anonymous href=../../../../../../../assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://iranzo.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://iranzo.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://iranzo.io/favicon-32x32.png><link rel=apple-touch-icon href=https://iranzo.io/apple-touch-icon.png><link rel=mask-icon href=https://iranzo.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=es href=https://iranzo.io/es/blog/2008/12/13/iscsi-y-clustering-en-rhel/centos/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-ZL9P943TP1"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-ZL9P943TP1")}</script><meta property="og:url" content="https://iranzo.io/es/blog/2008/12/13/iscsi-y-clustering-en-rhel/centos/"><meta property="og:site_name" content="Pablo Iranzo G√≥mez blog"><meta property="og:title" content="iSCSI y Clustering en RHEL/CentOS"><meta property="og:description" content="Introducci√≥n Durante la √∫ltima semana estuve jugando de nuevo con iSCSI en el curso de RH436 Enterprise Clustering and Storage Management. Hace tiempo hab√≠a seguido dos art√≠culos Instalando un target iSCSI y su continuaci√≥n Montando un iniciador iSCSI.
iSCSI es una tecnolog√≠a que permite acceder a almacenamiento remoto como si de unidades locales se tratara. A nivel ‚Äòbarato‚Äô, podemos utilizar el espacio de un servidor central del que hacemos copias de seguridad, etc para ofrecer ese almacenamiento a distintas m√°quinas."><meta property="og:locale" content="es"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2008-12-13T17:59:41+00:00"><meta property="article:modified_time" content="2023-08-25T09:48:47+00:00"><meta property="article:tag" content="Cluster"><meta property="article:tag" content="RHEL"><meta property="article:tag" content="Centos"><meta property="article:tag" content="Foss"><meta property="og:image" content="https://iranzo.io/mugshot.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://iranzo.io/mugshot.png"><meta name=twitter:title content="iSCSI y Clustering en RHEL/CentOS"><meta name=twitter:description content="Introducci√≥n
Durante la √∫ltima semana estuve jugando de nuevo con iSCSI en el curso de RH436 Enterprise Clustering and Storage Management. Hace tiempo hab√≠a seguido dos art√≠culos Instalando un target iSCSI y su continuaci√≥n Montando un iniciador iSCSI.
iSCSI es una tecnolog√≠a que permite acceder a almacenamiento remoto como si de unidades locales se tratara. A nivel &lsquo;barato&rsquo;, podemos utilizar el espacio de un servidor central del que hacemos copias de seguridad, etc para ofrecer ese almacenamiento a distintas m√°quinas."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blogs","item":"https://iranzo.io/es/blog/"},{"@type":"ListItem","position":2,"name":"iSCSI y Clustering en RHEL/CentOS","item":"https://iranzo.io/es/blog/2008/12/13/iscsi-y-clustering-en-rhel/centos/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"iSCSI y Clustering en RHEL/CentOS","name":"iSCSI y Clustering en RHEL\/CentOS","description":"Introducci√≥n Durante la √∫ltima semana estuve jugando de nuevo con iSCSI en el curso de RH436 Enterprise Clustering and Storage Management. Hace tiempo hab√≠a seguido dos art√≠culos Instalando un target iSCSI y su continuaci√≥n Montando un iniciador iSCSI.\niSCSI es una tecnolog√≠a que permite acceder a almacenamiento remoto como si de unidades locales se tratara. A nivel \u0026lsquo;barato\u0026rsquo;, podemos utilizar el espacio de un servidor central del que hacemos copias de seguridad, etc para ofrecer ese almacenamiento a distintas m√°quinas.\n","keywords":["cluster","rhel","centos","foss"],"articleBody":"Introducci√≥n Durante la √∫ltima semana estuve jugando de nuevo con iSCSI en el curso de RH436 Enterprise Clustering and Storage Management. Hace tiempo hab√≠a seguido dos art√≠culos Instalando un target iSCSI y su continuaci√≥n Montando un iniciador iSCSI.\niSCSI es una tecnolog√≠a que permite acceder a almacenamiento remoto como si de unidades locales se tratara. A nivel ‚Äòbarato‚Äô, podemos utilizar el espacio de un servidor central del que hacemos copias de seguridad, etc para ofrecer ese almacenamiento a distintas m√°quinas.\nCon la entrada en juego de las ofertas de virtualizaci√≥n integradas con el SO, como por ejemplo Xen, podemos tener un servidor ‚Äògrande‚Äô y potente que albergue distintas m√°quinas virtuales que sirvan las p√°ginas de dicho volumen en red, actualizarlo centralmente y tener muchos servidores actualizados‚Ä¶.\nBueno, a medias :-)\nSiempre es complicado compartir sistemas de ficheros, existen problemas de bloqueos de ficheros, accesos recurrentes, etc, en el caso de iSCSI no s√≥lo es el FS sino la unidad, desde cualquier equipo podemos particionarla, etc, es por ello que se necesitan algunas utilidades preparadas para dicho funcionamiento en red, as√≠ como por supuesto, un sistema de ficheros que soporte dicho uso simult√°neo.\nCon las √∫ltimas versiones del kernel, disponemos tanto de clvm (Cluster LVM) como de GFS (Global File System), que permiten, por un lado, poder operar en red desde varios equipos con los vol√∫menes l√≥gicos, redimensionarlos, etc sin afectar a la producci√≥n, como de un sistema de ficheros preparado para trabajar en red con varios equipos.\nPiensa por un momento, la posibilidad de tener ese host tan potente o una SAN con copias de seguridad bien controladas, etc\nA√±√°dele la posibilidad de tener m√°quinas virtuales que monten por la red una unidad iSCSI.\nA√±√°dele que esa unidad iSCSI puede ser de Lectura escritura, y que puedes utilizar enlaces simb√≥licos con variables que seg√∫n el host que acceda guarde los logs en una carpeta.\nImagina lanzar tantas m√°quinas virtuales como sea necesario para atender la demanda, poder distribuirlas en la red.\nManos a la obra Target iSCSI Si no tenemos un target iSCSI, podemos definirlo en nuestro anfitri√≥n, utilizando la versi√≥n Tech Preview de iSCSI Target llamada: scsi-target-utils\nEsta utilidad contiene un comando tgtadm que podemos utilizar para definir las unidades.\nDeberemos activar el demonio de tgtd para que est√© disponible en cada arranque con los comandos:\n#!bash chkconfig tgtd on service tgtd start Actualmente y como tech preview, debemos repetir cada vez los comandos que necesitamos para definir la unidad iSCSI, por ejemplo:\n#!bash tgtadm --lld iscsi --mode target --op new --tid=1 --targetname iqn.2008-12.tld.dominio.maquina:TARGET tgtadm --lld iscsi --mode logicalunit --op new --tid=1 --lun=1 -b /dev/vg0/TARGET tgtadm --mode target --op bind --tid=1 --initiator-address=14.14.14.14 Con estos comandos definimos un nuevo target con ID 1, de nombre IQN iqn.2008-12.tld.dominio.maquina:TARGET y le a√±adimos una unidad l√≥gica (LUN) que se basa en el contenido del volumen LVM /dev/vg0/TARGET.\nAdem√°s, le permitimos el acceso a dicho target desde la ip 14.14.14.14\nSi todo esto est√° bien, deberemos, hasta que salga de la Tech Preview, a√±adir estos comandos al fichero /etc/rc.local para que se ejecuten en cada arranque\nResto de equipos El primer paso, es instalar en todas las m√°quinas los paquetes de lvm2-cluster, as√≠ como ricci. En todas ellas deberemos ejecutar lvm ‚Äîenable-cluster para modificar los par√°metros de locking para utilizarlo en red.\nPara arrancar ricci tendremos que hacer algo parecido a lo que hicimos con tgtd\n#!bash chkconfig ricci on service ricci start` Por otro lado necesitaremos tener kmod-gfs, gfs-util y iscsi-initiator-utils.\nLas unidades iSCSI se reconocer√°n a partir de la primera detecci√≥n de forma autom√°tica, para ello deberemos ejecutar los siguientes comandos:\n#!bash iscsiadm -m discovery -t sendtargets -p IPTARGETISCSI iscsiadm -m node -T iqn.2008-12.tld.dominio.maquina:TARGET -l Que descubrir√° los targets disponibles para nuestra IP y luego har√° ‚Äôlogin‚Äô en la m√°quina. A partir de este momento tendremos nuevas unidades disponibles que se presentar√°n como SCSI a nuestro pc, podremos particionarlas, etc.\nEl cl√∫ster Si queremos hacer las cosas de la forma ‚Äòsencilla‚Äô, deberemos instalar luci en una de las m√°quinas, ya sea en un nodo de control, o en el anfitri√≥n Xen.\nLuci es un interfaz web que permite la gesti√≥n y creaci√≥n de clusters y para ello utiliza el demonio ‚Äòricci‚Äô que hemos instalado en cada m√°quina.\nSi tenemos las m√°quinas configuradas con los repositorios necesarios, ricci se har√° cargo de la instalaci√≥n de los paquetes necesarios para configurar todo.\nDesde el interfaz web de Luci podemos ir a√±adiendo cada uno de los nodos a utilizar, indicando sus claves de ‚Äòroot‚Äô y se encargar√° de contactarlos y a trav√©s de ricci, instalar el software necesario y reiniciarlos para integrarlos en el cluster.\nLos nodos, una vez en el cluster pueden utilizarse para albergar servicios, que est√©n de forma exclusiva (por ejemplo una bbdd porque necesite prioridad absoluta), o bien en failover para que no se deje de dar el servicio.\nPor defecto tenemos una serie de servicios preconfigurados que podemos dar, como http, nfs, etc que podremos configurar r√°pidamente desde luci, que se encargar√° de desplegar dicha configuraci√≥n a todo el cluster.\nLa forma de hacerlo es sencilla, se definen recursos (IP, NFS Exports, NFS Clients, http, mount points) que luego se agrupan por cadenas de dependencia en servicios y se les asignan grupos de failover, para que en caso de fallo, podamos definir prioridades.\nImagina el caso de una empresa con dos servidores, uno con la BBDD y otro con la web. En caso de fallo de uno de ellos, podemos hacer ‚Äòsaltar‚Äô los servicios a la m√°quina que est√° operativa hasta que arreglemos la da√±ada y luego, cada servicio, volver√≠a a su m√°quina ‚Äòpreferida‚Äô o en el orden necesario.\nEn el caso de m√°quinas virtuales, en caso de que dejen de responder, CMAN realizar√° un reinicio (siempre que hayamos distribuido las claves de xen que podemos crear en la interfaz tanto a los guests como al anfitri√≥n que estar√° escuchando con el demonio de fencing para XVM activado).\nEn el caso de tener enchufes ‚Äòcon red‚Äô o bien m√°quinas con tarjetas de gesti√≥n remota (iLO, RemoteView Service Board, etc), definiremos los par√°metros de acceso.\nEn caso de detectar un problema con cualquier equipo, el resto de ellos har√° votaciones y si la mayor√≠a considera que no responde, lo reiniciar√°n, por un lado para liberar cualquier tipo de acceso a disco, etc que hubiera estado haciendo a los recursos del cluster, como para intentar recuperarlo.\nGFS: Global File System ¬øQu√© pinta GFS en todo esto?\nGFS1 nos permite crear un sistema de ficheros que tendr√° un journal para cada nodo del cluster y que si lo creamos sobre el volumen iSCSI podemos hacer disponible a todos los equipos, si un equipo se bloquea, otro toma el control del journal no acabado, lo verifica y aplica sobre el FS hasta que la m√°quina retorna para dejarlo en un estado limpio.\nPor otro lado, CLVM y GFS permiten aumentar din√°micamente el tama√±o de los vol√∫menes, de forma que no tenemos que dejar inoperativos nuestros sistemas para hacer mantenimientos par a√±adir m√°s capacidad, etc.\nPermite tambi√©n crear enlaces simb√≥licos de forma que una unidad con FS GFS1 pueda quedar:\nhosts/ hosts/host1/logs hosts/host2/logs hosts/host3/logs hosts/host4/logs hosts/host5/logs logs -\u003e hosts/@hostname/logs/ Esto permite que diversos servidores web tengan configurado como ruta para los logs la carpeta ‚Äôlogs‚Äô que se expandir√° al hostname de la m√°quina, haciendo que queden todos recogidos en un lugar central para posterior an√°lisis de estad√≠sticas, etc\nEste tipo de enlaces se denominan CDPN: Context-dependent pathnames y nos permiten jugar con este tipo de cosas y aprovechar las ventajas de un almacenamiento √∫nico.\n¬øY si falla la red Como siempre podemos tener problemas con la red, la forma de solucionarlos consiste en tener varios interfaces de red en los equipos a trav√©s de distintos switches, etc y en las m√°quinas, una vez descubiertos los targets, configurar el fichero /etc/multipathd.conf y habilitar el demonio.\nNos crear√° las rutas necesarias y una serie de dispositivos /dev/mpath/* para acceder de forma tolerante a fallos a nuestros recursos, si configuramos las tarjetas de red en modo bonding, ya tenemos el acceso m√°s o menos asegurado ante las cat√°strofes m√°s comunes y nuestros datos disponibles\nConclusi√≥n Tenemos a nuestro alcance muchas herramientas para hacer sencilla la utilizaci√≥n y creaci√≥n de sistemas equivalentes a lo que hace a√±os s√≥lo ten√≠a una alternativa excesivamente cara.\nSinceramente vale la pena perder un rato y probar estas cosas y maravillarnos de las posibilidades que abre de cara a la gesti√≥n de los equipos, la informaci√≥n y su acceso y lo mejor de todo, siempre con Software Libre.\nEspero que esta introducci√≥n os despierte el gusanillo para explorar las diversas funcionalidades que estas tecnolog√≠as nos ofrecen! Disfruta! (y si lo haces, puedes Invitarme a un caf√© ) ","wordCount":"1453","inLanguage":"es","image":"https://iranzo.io/mugshot.png","datePublished":"2008-12-13T17:59:41Z","dateModified":"2023-08-25T09:48:47.077Z","author":{"@type":"Person","name":"Pablo Iranzo G√≥mez"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://iranzo.io/es/blog/2008/12/13/iscsi-y-clustering-en-rhel/centos/"},"publisher":{"@type":"Organization","name":"Pablo Iranzo G√≥mez blog","logo":{"@type":"ImageObject","url":"https://iranzo.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://iranzo.io/es/ accesskey=h title="Home (Alt + H)"><img src=https://iranzo.io/apple-icon-152x152.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://iranzo.io/ title=English aria-label=English>En</a></li></ul></div></div><ul id=menu><li><a href=https://iranzo.io/es/ title=üè†Home><span>üè†Home</span></a></li><li><a href=https://iranzo.io/es/about/ title=üóíÔ∏èAbout><span>üóíÔ∏èAbout</span></a></li><li><a href=https://iranzo.io/es/redken_bot/ title=üêòredken_bot><span>üêòredken_bot</span></a></li><li><a href=https://iranzo.io/es/projects/ title=üìêProjects><span>üìêProjects</span></a></li><li><a href=https://iranzo.io/es/archives/ title="üóÑÔ∏è Archives"><span>üóÑÔ∏è Archives</span></a></li><li><a href=https://iranzo.io/es/categories/ title=üó∫Ô∏èCategories><span>üó∫Ô∏èCategories</span></a></li><li><a href=https://iranzo.io/es/tags/ title=üè∑Ô∏èTags><span>üè∑Ô∏èTags</span></a></li><li><a href=https://iranzo.io/es/search title="üîéSearch (Alt + /)" accesskey=/><span>üîéSearch</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://iranzo.io/es/>Inicio</a>&nbsp;¬ª&nbsp;<a href=https://iranzo.io/es/blog/>Blogs</a></div><h1 class="post-title entry-hint-parent">iSCSI y Clustering en RHEL/CentOS</h1><div class=post-meta><span title='2008-12-13 17:59:41 +0000 UTC'>diciembre 13, 2008</span>&nbsp;¬∑&nbsp;7 min&nbsp;¬∑&nbsp;Pablo Iranzo G√≥mez</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Tabla de Contenidos</span></summary><div class=inner><ul><li><a href=#introducci%c3%b3n aria-label=Introducci√≥n>Introducci√≥n</a></li><li><a href=#manos-a-la-obra aria-label="Manos a la obra">Manos a la obra</a><ul><li><a href=#target-iscsi aria-label="Target iSCSI">Target iSCSI</a></li><li><a href=#resto-de-equipos aria-label="Resto de equipos">Resto de equipos</a></li><li><a href=#el-cl%c3%baster aria-label="El cl√∫ster">El cl√∫ster</a></li><li><a href=#gfs-global-file-system aria-label="GFS: Global File System">GFS: Global File System</a></li><li><a href=#y-si-falla-la-red aria-label="¬øY si falla la red">¬øY si falla la red</a></li><li><a href=#conclusi%c3%b3n aria-label=Conclusi√≥n>Conclusi√≥n</a></li></ul></li></ul></div></details></div><div class=post-content><h2 id=introducci√≥n>Introducci√≥n<a hidden class=anchor aria-hidden=true href=#introducci√≥n>#</a></h2><p>Durante la √∫ltima semana estuve jugando de nuevo con iSCSI en el curso de <a href=http://www.redhat.es/training/course/RH436>RH436 Enterprise Clustering and Storage Management</a>. Hace tiempo hab√≠a seguido dos art√≠culos <a href=http://federicosayd.wordpress.com/2007/09/11/instalando-un-target-iscsi/>Instalando un target iSCSI</a> y su continuaci√≥n <a href=http://federicosayd.wordpress.com/2007/09/13/montando-un-iniciador-iscsi-en-linux/>Montando un iniciador iSCSI</a>.</p><p>iSCSI es una tecnolog√≠a que permite acceder a almacenamiento remoto como si de unidades locales se tratara. A nivel &lsquo;barato&rsquo;, podemos utilizar el espacio de un servidor central del que hacemos copias de seguridad, etc para ofrecer ese almacenamiento a distintas m√°quinas.</p><p>Con la entrada en juego de las ofertas de virtualizaci√≥n integradas con el SO, como por ejemplo Xen, podemos tener un servidor &lsquo;grande&rsquo; y potente que albergue distintas m√°quinas virtuales que sirvan las p√°ginas de dicho volumen en red, actualizarlo centralmente y tener muchos servidores actualizados&mldr;.</p><p>Bueno, a medias :-)</p><p>Siempre es complicado compartir sistemas de ficheros, existen problemas de bloqueos de ficheros, accesos recurrentes, etc, en el caso de iSCSI no s√≥lo es el FS sino la unidad, desde cualquier equipo podemos particionarla, etc, es por ello que se necesitan algunas utilidades preparadas para dicho funcionamiento en red, as√≠ como por supuesto, un sistema de ficheros que soporte dicho uso simult√°neo.</p><p>Con las √∫ltimas versiones del kernel, disponemos tanto de clvm (Cluster <a href=../../../../../../../es/blog/2007/03/09/Gestor-de-Volumenes-Logicos-LVM/>LVM</a>) como de GFS (Global File System), que permiten, por un lado, poder operar en red desde varios equipos con los vol√∫menes l√≥gicos, redimensionarlos, etc sin afectar a la producci√≥n, como de un sistema de ficheros preparado para trabajar en red con varios equipos.</p><p>Piensa por un momento, la posibilidad de tener ese host tan potente o una SAN con copias de seguridad bien controladas, etc</p><p>A√±√°dele la posibilidad de tener m√°quinas virtuales que monten por la red una unidad iSCSI.</p><p>A√±√°dele que esa unidad iSCSI puede ser de Lectura escritura, y que puedes utilizar enlaces simb√≥licos con variables que seg√∫n el host que acceda guarde los logs en una carpeta.</p><p>Imagina lanzar tantas m√°quinas virtuales como sea necesario para atender la demanda, poder distribuirlas en la red.</p><h2 id=manos-a-la-obra>Manos a la obra<a hidden class=anchor aria-hidden=true href=#manos-a-la-obra>#</a></h2><h3 id=target-iscsi>Target iSCSI<a hidden class=anchor aria-hidden=true href=#target-iscsi>#</a></h3><p>Si no tenemos un target iSCSI, podemos definirlo en nuestro anfitri√≥n, utilizando la versi√≥n Tech Preview de iSCSI Target llamada: <code>scsi-target-utils</code></p><p>Esta utilidad contiene un comando <code>tgtadm</code> que podemos utilizar para definir las unidades.</p><p>Deberemos activar el demonio de tgtd para que est√© disponible en cada arranque con los comandos:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>#!bash
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>chkconfig tgtd on
</span></span><span style=display:flex><span>service tgtd start
</span></span></code></pre></div><p>Actualmente y como tech preview, debemos repetir cada vez los comandos que necesitamos para definir la unidad iSCSI, por ejemplo:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>#!bash
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>tgtadm --lld iscsi --mode target --op new --tid<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span> --targetname iqn.2008-12.tld.dominio.maquina:TARGET tgtadm --lld iscsi --mode logicalunit --op new --tid<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span> --lun<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span> -b /dev/vg0/TARGET tgtadm --mode target --op bind --tid<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span> --initiator-address<span style=color:#f92672>=</span>14.14.14.14
</span></span></code></pre></div><p>Con estos comandos definimos un nuevo target con ID 1, de nombre IQN <code>iqn.2008-12.tld.dominio.maquina:TARGET</code> y le a√±adimos una unidad l√≥gica (LUN) que se basa en el contenido del volumen LVM /dev/vg0/TARGET.</p><p>Adem√°s, le permitimos el acceso a dicho target desde la ip <code>14.14.14.14</code></p><p>Si todo esto est√° bien, deberemos, hasta que salga de la Tech Preview, a√±adir estos comandos al fichero <code>/etc/rc.local</code> para que se ejecuten en cada arranque</p><h3 id=resto-de-equipos>Resto de equipos<a hidden class=anchor aria-hidden=true href=#resto-de-equipos>#</a></h3><p>El primer paso, es instalar en todas las m√°quinas los paquetes de <code>lvm2-cluster</code>, as√≠ como <code>ricci</code>. En todas ellas deberemos ejecutar <code>lvm ‚Äîenable-cluster</code> para modificar los par√°metros de locking para utilizarlo en red.</p><p>Para arrancar ricci tendremos que hacer algo parecido a lo que hicimos con tgtd</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>#!bash
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>chkconfig ricci on
</span></span><span style=display:flex><span>service ricci start<span style=color:#e6db74>`</span>
</span></span></code></pre></div><p>Por otro lado necesitaremos tener <code>kmod-gfs</code>, <code>gfs-util</code> y <code>iscsi-initiator-utils</code>.</p><p>Las unidades iSCSI se reconocer√°n a partir de la primera detecci√≥n de forma autom√°tica, para ello deberemos ejecutar los siguientes comandos:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>#!bash
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>iscsiadm -m discovery -t sendtargets -p IPTARGETISCSI iscsiadm -m node -T iqn.2008-12.tld.dominio.maquina:TARGET -l
</span></span></code></pre></div><p>Que descubrir√° los targets disponibles para nuestra IP y luego har√° &rsquo;login&rsquo; en la m√°quina. A partir de este momento tendremos nuevas unidades disponibles que se presentar√°n como SCSI a nuestro pc, podremos
particionarlas, etc.</p><h3 id=el-cl√∫ster>El cl√∫ster<a hidden class=anchor aria-hidden=true href=#el-cl√∫ster>#</a></h3><p>Si queremos hacer las cosas de la forma &lsquo;sencilla&rsquo;, deberemos instalar <code>luci</code> en una de las m√°quinas, ya sea en un nodo de control, o en el anfitri√≥n Xen.</p><p>Luci es un interfaz web que permite la gesti√≥n y creaci√≥n de clusters y para ello utiliza el demonio &lsquo;ricci&rsquo; que hemos instalado en cada m√°quina.</p><p>Si tenemos las m√°quinas configuradas con los repositorios necesarios, <code>ricci</code> se har√° cargo de la instalaci√≥n de los paquetes necesarios para configurar todo.</p><p>Desde el interfaz web de Luci podemos ir a√±adiendo cada uno de los nodos a utilizar, indicando sus claves de &lsquo;root&rsquo; y se encargar√° de contactarlos y a trav√©s de ricci, instalar el software necesario y reiniciarlos para integrarlos en el cluster.</p><p>Los nodos, una vez en el cluster pueden utilizarse para albergar servicios, que est√©n de forma exclusiva (por ejemplo una bbdd porque necesite prioridad absoluta), o bien en failover para que no se deje de dar el servicio.</p><p>Por defecto tenemos una serie de servicios preconfigurados que podemos dar, como http, nfs, etc que podremos configurar r√°pidamente desde luci, que se encargar√° de desplegar dicha configuraci√≥n a todo el cluster.</p><p>La forma de hacerlo es sencilla, se definen recursos (IP, NFS Exports, NFS Clients, http, mount points) que luego se agrupan por cadenas de dependencia en servicios y se les asignan grupos de failover, para que en caso de fallo, podamos definir prioridades.</p><p>Imagina el caso de una empresa con dos servidores, uno con la BBDD y otro con la web. En caso de fallo de uno de ellos, podemos hacer &lsquo;saltar&rsquo; los servicios a la m√°quina que est√° operativa hasta que arreglemos la da√±ada y luego, cada servicio, volver√≠a a su m√°quina &lsquo;preferida&rsquo; o en el orden necesario.</p><p>En el caso de m√°quinas virtuales, en caso de que dejen de responder, CMAN realizar√° un reinicio (siempre que hayamos distribuido las claves de xen que podemos crear en la interfaz tanto a los guests como al anfitri√≥n que estar√° escuchando con el demonio de fencing para XVM activado).</p><p>En el caso de tener enchufes &lsquo;con red&rsquo; o bien m√°quinas con tarjetas de gesti√≥n remota (iLO, RemoteView Service Board, etc), definiremos los par√°metros de acceso.</p><p>En caso de detectar un problema con cualquier equipo, el resto de ellos har√° votaciones y si la mayor√≠a considera que no responde, lo reiniciar√°n, por un lado para liberar cualquier tipo de acceso a disco, etc que hubiera estado haciendo a los recursos del cluster, como para intentar recuperarlo.</p><h3 id=gfs-global-file-system>GFS: Global File System<a hidden class=anchor aria-hidden=true href=#gfs-global-file-system>#</a></h3><p>¬øQu√© pinta GFS en todo esto?</p><p>GFS1 nos permite crear un sistema de ficheros que tendr√° un journal para cada nodo del cluster y que si lo creamos sobre el volumen iSCSI podemos hacer disponible a todos los equipos, si un equipo se bloquea, otro toma el control del journal no acabado, lo verifica y aplica sobre el FS hasta que la m√°quina retorna para dejarlo en un estado limpio.</p><p>Por otro lado, CLVM y GFS permiten aumentar din√°micamente el tama√±o de los vol√∫menes, de forma que no tenemos que dejar inoperativos nuestros sistemas para hacer mantenimientos par a√±adir m√°s capacidad, etc.</p><p>Permite tambi√©n crear enlaces simb√≥licos de forma que una unidad con FS GFS1 pueda quedar:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>hosts/
</span></span><span style=display:flex><span>hosts/host1/logs
</span></span><span style=display:flex><span>hosts/host2/logs
</span></span><span style=display:flex><span>hosts/host3/logs
</span></span><span style=display:flex><span>hosts/host4/logs
</span></span><span style=display:flex><span>hosts/host5/logs
</span></span><span style=display:flex><span>logs -&gt; hosts/@hostname/logs/
</span></span></code></pre></div><p>Esto permite que diversos servidores web tengan configurado como ruta para los logs la carpeta &rsquo;logs&rsquo; que se expandir√° al hostname de la m√°quina, haciendo que queden todos recogidos en un lugar central para posterior an√°lisis de estad√≠sticas, etc</p><p>Este tipo de enlaces se denominan CDPN: Context-dependent pathnames y nos permiten jugar con este tipo de cosas y aprovechar las ventajas de un almacenamiento √∫nico.</p><h3 id=y-si-falla-la-red>¬øY si falla la red<a hidden class=anchor aria-hidden=true href=#y-si-falla-la-red>#</a></h3><p>Como siempre podemos tener problemas con la red, la forma de solucionarlos consiste en tener varios interfaces de red en los equipos a trav√©s de distintos switches, etc y en las m√°quinas, una vez descubiertos los targets, configurar el fichero <code>/etc/multipathd.conf</code> y habilitar el demonio.</p><p>Nos crear√° las rutas necesarias y una serie de dispositivos <code>/dev/mpath/*</code> para acceder de forma tolerante a fallos a nuestros recursos, si configuramos las tarjetas de red en modo bonding, ya tenemos el acceso m√°s o menos asegurado ante las cat√°strofes m√°s comunes y nuestros datos disponibles</p><h3 id=conclusi√≥n>Conclusi√≥n<a hidden class=anchor aria-hidden=true href=#conclusi√≥n>#</a></h3><p>Tenemos a nuestro alcance muchas herramientas para hacer sencilla la utilizaci√≥n y creaci√≥n de sistemas equivalentes a lo que hace a√±os s√≥lo ten√≠a una alternativa excesivamente cara.</p><p>Sinceramente vale la pena perder un rato y probar estas cosas y maravillarnos de las posibilidades que abre de cara a la gesti√≥n de los equipos, la informaci√≥n y su acceso y lo mejor de todo, siempre con Software Libre.</p><p>Espero que esta introducci√≥n os despierte el gusanillo para explorar las diversas funcionalidades que estas tecnolog√≠as nos ofrecen!<p>Disfruta! (y si lo haces, puedes
<a href=https://ko-fi.com/I2I4KDA0V target=_blank><img src=https://storage.ko-fi.com/cdn/brandasset/kofi_s_logo_nolabel.png height=36 style=border:0;height:36px;vertical-align:middle;display:inline-block border=0>
</img>
Invitarme a un caf√©
</a>)</p></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://iranzo.io/es/tags/cluster/>Cluster</a></li><li><a href=https://iranzo.io/es/tags/rhel/>RHEL</a></li><li><a href=https://iranzo.io/es/tags/centos/>Centos</a></li><li><a href=https://iranzo.io/es/tags/foss/>Foss</a></li></ul><nav class=paginav><a class=prev href=https://iranzo.io/es/blog/2008/12/13/migrar-de-spip-1.9-a-2.0/><span class=title>¬´ Anterior</span><br><span>Migrar de SPIP 1.9 a 2.0</span>
</a><a class=next href=https://iranzo.io/es/blog/2008/11/08/tablas-para-no-decir-nada/><span class=title>Siguiente ¬ª</span><br><span>Tablas para no decir nada</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share iSCSI y Clustering en RHEL/CentOS on x" href="https://x.com/intent/tweet/?text=iSCSI%20y%20Clustering%20en%20RHEL%2fCentOS&amp;url=https%3a%2f%2firanzo.io%2fes%2fblog%2f2008%2f12%2f13%2fiscsi-y-clustering-en-rhel%2fcentos%2f&amp;hashtags=cluster%2crhel%2ccentos%2cfoss"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share iSCSI y Clustering en RHEL/CentOS on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2firanzo.io%2fes%2fblog%2f2008%2f12%2f13%2fiscsi-y-clustering-en-rhel%2fcentos%2f&amp;title=iSCSI%20y%20Clustering%20en%20RHEL%2fCentOS&amp;summary=iSCSI%20y%20Clustering%20en%20RHEL%2fCentOS&amp;source=https%3a%2f%2firanzo.io%2fes%2fblog%2f2008%2f12%2f13%2fiscsi-y-clustering-en-rhel%2fcentos%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share iSCSI y Clustering en RHEL/CentOS on reddit" href="https://reddit.com/submit?url=https%3a%2f%2firanzo.io%2fes%2fblog%2f2008%2f12%2f13%2fiscsi-y-clustering-en-rhel%2fcentos%2f&title=iSCSI%20y%20Clustering%20en%20RHEL%2fCentOS"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share iSCSI y Clustering en RHEL/CentOS on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2firanzo.io%2fes%2fblog%2f2008%2f12%2f13%2fiscsi-y-clustering-en-rhel%2fcentos%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share iSCSI y Clustering en RHEL/CentOS on whatsapp" href="https://api.whatsapp.com/send?text=iSCSI%20y%20Clustering%20en%20RHEL%2fCentOS%20-%20https%3a%2f%2firanzo.io%2fes%2fblog%2f2008%2f12%2f13%2fiscsi-y-clustering-en-rhel%2fcentos%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share iSCSI y Clustering en RHEL/CentOS on telegram" href="https://telegram.me/share/url?text=iSCSI%20y%20Clustering%20en%20RHEL%2fCentOS&amp;url=https%3a%2f%2firanzo.io%2fes%2fblog%2f2008%2f12%2f13%2fiscsi-y-clustering-en-rhel%2fcentos%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share iSCSI y Clustering en RHEL/CentOS on ycombinator" href="https://news.ycombinator.com/submitlink?t=iSCSI%20y%20Clustering%20en%20RHEL%2fCentOS&u=https%3a%2f%2firanzo.io%2fes%2fblog%2f2008%2f12%2f13%2fiscsi-y-clustering-en-rhel%2fcentos%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://iranzo.io/es/>Pablo Iranzo G√≥mez blog</a></span> ¬∑
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg></a><center><small>This blog is a participant in the Amazon Associate Program, an affiliate advertising program designed to provide a means for sites to earn advertising fees by advertising and linking to Amazon.</small></center><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copiar";function s(){t.innerHTML="¬°copiado!",setTimeout(()=>{t.innerHTML="copiar"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>